{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"10aX5PdAow9IbfmhhGPLivGnjBKnM0-au","timestamp":1663645162447}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install gluonnlp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"akd-clSeOtO2","executionInfo":{"status":"ok","timestamp":1665810607186,"user_tz":-540,"elapsed":7553,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}},"outputId":"eea0a50b-b6c8-41d2-c517-5fa50f4f0fc1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gluonnlp\n","  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 40 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 81 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 92 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 296 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 307 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 317 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 327 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 337 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 344 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.21.6)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.32)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (3.0.9)\n","Building wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595737 sha256=562f368490fec6ee340f218d5dfb145fbcf9617435a44b26609ef3816c45b96d\n","  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n","Successfully built gluonnlp\n","Installing collected packages: gluonnlp\n","Successfully installed gluonnlp-0.10.0\n"]}]},{"cell_type":"code","source":["!pip install mxnet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dbC39TYSO0zn","executionInfo":{"status":"ok","timestamp":1665810616369,"user_tz":-540,"elapsed":9189,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}},"outputId":"039790ff-db0e-40ad-c2f4-cd757db302bf"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mxnet\n","  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n","\u001b[K     |████████████████████████████████| 49.1 MB 153 kB/s \n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.21.6)\n","Collecting graphviz<0.9.0,>=0.8.1\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n","Installing collected packages: graphviz, mxnet\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","Successfully installed graphviz-0.8.4 mxnet-1.9.1\n"]}]},{"cell_type":"code","source":["!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j4PjkcCIO_Zv","executionInfo":{"status":"ok","timestamp":1665810744949,"user_tz":-540,"elapsed":128589,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}},"outputId":"a92b63fa-6a47-4d09-8c2e-5e8de8707f07"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n","  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-p6uggj5a\n","  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-p6uggj5a\n","Collecting boto3<=1.15.18\n","  Downloading boto3-1.15.18-py2.py3-none-any.whl (129 kB)\n","\u001b[K     |████████████████████████████████| 129 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: gluonnlp<=0.10.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.10.0)\n","Collecting mxnet<=1.7.0.post2,>=1.4.0\n","  Downloading mxnet-1.7.0.post2-py2.py3-none-manylinux2014_x86_64.whl (54.7 MB)\n","\u001b[K     |████████████████████████████████| 54.7 MB 18 kB/s \n","\u001b[?25hCollecting onnxruntime<=1.8.0,==1.8.0\n","  Downloading onnxruntime-1.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n","\u001b[K     |████████████████████████████████| 4.5 MB 62.6 MB/s \n","\u001b[?25hCollecting sentencepiece<=0.1.96,>=0.1.6\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 51.1 MB/s \n","\u001b[?25hCollecting torch<=1.10.1,>=1.7.0\n","  Downloading torch-1.10.1-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n","\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.2 MB/s eta 0:00:41tcmalloc: large alloc 1147494400 bytes == 0x3a1fe000 @  0x7f8467f5e615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n","\u001b[K     |████████████████████████████████| 881.9 MB 16 kB/s \n","\u001b[?25hCollecting transformers<=4.8.1,>=4.8.1\n","  Downloading transformers-4.8.1-py3-none-any.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 46.7 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (3.17.3)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.12)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.21.6)\n","Collecting s3transfer<0.4.0,>=0.3.0\n","  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n","\u001b[K     |████████████████████████████████| 73 kB 1.8 MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting botocore<1.19.0,>=1.18.18\n","  Downloading botocore-1.18.18-py2.py3-none-any.whl (6.7 MB)\n","\u001b[K     |████████████████████████████████| 6.7 MB 43.5 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (2.8.2)\n","Requirement already satisfied: urllib3<1.26,>=1.20 in /usr/local/lib/python3.7/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.24.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (21.3)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (0.29.32)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (0.8.4)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.23.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2022.9.24)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.10.1,>=1.7.0->kobert==0.2.3) (4.1.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (2022.6.2)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 49.6 MB/s \n","\u001b[?25hCollecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 65.8 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.64.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (5.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.9.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.2.0)\n","Building wheels for collected packages: kobert, sacremoses\n","  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert: filename=kobert-0.2.3-py3-none-any.whl size=15708 sha256=fa42d7fb14926bcce62778f1485cd8a540522a20ad1b3316f97d7e8f0a88db7c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-nhxhfee3/wheels/d3/68/ca/334747dfb038313b49cf71f84832a33372f3470d9ddfd051c0\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=2f1b9e237761a31f77606556ec40393a30e2dc52fb5be09b488202e9a5b231eb\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built kobert sacremoses\n","Installing collected packages: jmespath, botocore, tokenizers, sacremoses, s3transfer, huggingface-hub, transformers, torch, sentencepiece, onnxruntime, mxnet, boto3, kobert\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","  Attempting uninstall: mxnet\n","    Found existing installation: mxnet 1.9.1\n","    Uninstalling mxnet-1.9.1:\n","      Successfully uninstalled mxnet-1.9.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.15.18 botocore-1.18.18 huggingface-hub-0.0.12 jmespath-0.10.0 kobert-0.2.3 mxnet-1.7.0.post2 onnxruntime-1.8.0 s3transfer-0.3.7 sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.10.3 torch-1.10.1 transformers-4.8.1\n"]}]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","from torch.utils.data import Dataset\n","from torch import optim\n","import numpy as np"],"metadata":{"id":"DJDXqtKENJgx","executionInfo":{"status":"ok","timestamp":1665810745852,"user_tz":-540,"elapsed":924,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import gluonnlp as nlp"],"metadata":{"id":"NyCL1RQkULc1","executionInfo":{"status":"ok","timestamp":1665810749184,"user_tz":-540,"elapsed":3335,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm, tqdm_notebook"],"metadata":{"id":"Lj1uaZ7hOdb_","executionInfo":{"status":"ok","timestamp":1665810749184,"user_tz":-540,"elapsed":3,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup"],"metadata":{"id":"584TcA4ROaYg","executionInfo":{"status":"ok","timestamp":1665810755860,"user_tz":-540,"elapsed":6678,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["from kobert import get_pytorch_kobert_model\n","from kobert.utils import get_tokenizer"],"metadata":{"id":"ULFvPE5HSkn2","executionInfo":{"status":"ok","timestamp":1665810756230,"user_tz":-540,"elapsed":390,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pdo7OD2vOI5P","executionInfo":{"status":"ok","timestamp":1665810807638,"user_tz":-540,"elapsed":51410,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}},"outputId":"4756216b-e913-4a2d-9c34-d530a4c79fab"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# GPU 설정\n","device = torch.device(\"cuda:0\")"],"metadata":{"id":"yO2c4giFVFKe","executionInfo":{"status":"ok","timestamp":1665810807639,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#BERT 모델, Vocabulary 불러오기\n","bertmodel, vocab = get_pytorch_kobert_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S_R6da0DUgst","executionInfo":{"status":"ok","timestamp":1665810822074,"user_tz":-540,"elapsed":14439,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}},"outputId":"8842a4d9-4298-44ee-c712-7553ab177b33"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/.cache/kobert_v1.zip[██████████████████████████████████████████████████]\n","/content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece[██████████████████████████████████████████████████]\n"]}]},{"cell_type":"code","source":["#Setting parameters\n","max_len = 64\n","batch_size = 64\n","warmup_ratio = 0.1\n","num_epochs = 5\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate =  5e-5"],"metadata":{"id":"xAIHwNK4U1nA","executionInfo":{"status":"ok","timestamp":1665810822074,"user_tz":-540,"elapsed":31,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["#토큰화\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kYLeL6omSkl3","executionInfo":{"status":"ok","timestamp":1665810822075,"user_tz":-540,"elapsed":29,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}},"outputId":"0b4f830a-0c3c-41de-cf55-ce78e5dd68fb"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"]}]},{"cell_type":"code","source":["class BERTDataset(Dataset):\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n","                 pad, pair):\n","        transform = nlp.data.BERTSentenceTransform(\n","            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","\n","        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","        self.labels = [np.int32(i[label_idx]) for i in dataset]\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","    def __len__(self):\n","        return (len(self.labels))"],"metadata":{"id":"LeLH19hpR1rH","executionInfo":{"status":"ok","timestamp":1665810822075,"user_tz":-540,"elapsed":22,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes=20,   ##클래스 수 조정##\n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","                 \n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","    \n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","        \n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)"],"metadata":{"id":"-6Lm9E60N42g","executionInfo":{"status":"ok","timestamp":1665810822076,"user_tz":-540,"elapsed":22,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8xtwISQdNDrN","executionInfo":{"status":"ok","timestamp":1665810832523,"user_tz":-540,"elapsed":10468,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}},"outputId":"4614adc6-0f99-4d2b-a961-be501a4fd3a0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["BERTClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (classifier): Linear(in_features=768, out_features=21, bias=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n",")"]},"metadata":{},"execution_count":16}],"source":["model = torch.load('/content/drive/MyDrive/last_final_model.pt')\n","model.eval()"]},{"cell_type":"code","source":["def predict(predict_sentence,model):\n","    \n","    data = [predict_sentence, '0']\n","    dataset_another = [data]\n","\n","    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n","    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n","    \n","    model.eval()\n","\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","\n","        out = model(token_ids, valid_length, segment_ids)\n","\n","\n","        test_eval=[]\n","        for i in out:\n","            logits=i\n","            logits = logits.detach().cpu().numpy()\n","\n","            if np.argmax(logits) == 0:\n","                test_eval.append(\"편안함\")\n","            elif np.argmax(logits) == 1:\n","                test_eval.append(\"기쁨\")\n","            elif np.argmax(logits) == 2:\n","                test_eval.append(\"행복\")\n","            elif np.argmax(logits) == 3:\n","                test_eval.append(\"감사\")\n","            elif np.argmax(logits) == 4:\n","                test_eval.append(\"만족\")\n","            elif np.argmax(logits) == 5:\n","                test_eval.append(\"흥미로움\")\n","            elif np.argmax(logits) == 6:\n","                test_eval.append(\"기쁨\")\n","            elif np.argmax(logits) == 7:\n","                test_eval.append(\"슬픔\")\n","            elif np.argmax(logits) == 8:\n","                test_eval.append(\"당황\")\n","            elif np.argmax(logits) == 9:\n","                test_eval.append(\"상처\")\n","            elif np.argmax(logits) == 10:\n","                test_eval.append(\"불안\")\n","            elif np.argmax(logits) == 11:\n","                test_eval.append(\"짜증\")\n","            elif np.argmax(logits) == 12:\n","                test_eval.append(\"답답\")\n","            elif np.argmax(logits) == 13:\n","                test_eval.append(\"허무함\")\n","            elif np.argmax(logits) == 14:\n","                test_eval.append(\"조롱\")\n","            elif np.argmax(logits) == 15:\n","                test_eval.append(\"불편함\")\n","            elif np.argmax(logits) == 16:\n","                test_eval.append(\"걱정\")\n","            elif np.argmax(logits) == 17:\n","                test_eval.append(\"불만\")\n","            elif np.argmax(logits) == 18:\n","                test_eval.append(\"무서움\")\n","            elif np.argmax(logits) == 19:\n","                test_eval.append(\"보통\")\n","            else :\n","                test_eval.append(\"궁금\")\n","\n","        \n","    return test_eval[0]\n","\n","#        print('오늘의 기분은'+test_eval[0])"],"metadata":{"id":"Vf75QXlRRUom","executionInfo":{"status":"ok","timestamp":1665810832524,"user_tz":-540,"elapsed":20,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# text = open('/content/drive/MyDrive/text_file/test.txt', 'r')\n","# text = text.read().splitlines()\n","# print(text)"],"metadata":{"id":"eNV1TuDaOrj_","executionInfo":{"status":"ok","timestamp":1665810832524,"user_tz":-540,"elapsed":18,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# str = ''.join(text)"],"metadata":{"id":"MDxRuQLnSPTd","executionInfo":{"status":"ok","timestamp":1665810832525,"user_tz":-540,"elapsed":19,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# a = predict(str, model)"],"metadata":{"id":"j2-IjfVmSPMW","executionInfo":{"status":"ok","timestamp":1665810832525,"user_tz":-540,"elapsed":17,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["heal = ['여수 밤바다', '파주 평화누리공원', '순천 갈대밭', '제주도 해안도로', \n","         '진주 진양호', '장흥유원지', '대구 앞산정만대', '춘천 해피초원농장' ,' 속초 해수욕장', \n","         '경주 불국사', '포항 호미곶', '남해 두모마을', '대관령 하늘목장', '군산 철길마을', \n","         '국립 광릉수목원', '금선사 템플스테이', '보성 제암산자연휴양림','군산 선유도', '용인 에버랜드',\n","        '잠실 롯데월드', '경주 경주월드', '대구 이월드', '부산 롯데월드', '남원 광한루', '부산 해운대',\n","        '광안리해수욕장', '다대포해수욕장', '송정해수욕장', '거제도 매미성', '통영 해파랑길',\n","        '곡성 기차마을', '임실 치즈마을', '대관령 양떼목장', '남원 서도역', '정동진해수욕장',\n","        '강릉 강문해변', '담양 죽녹원', '전주 한옥마을', '제주 올레길', '순천 순천만', '춘천 남이섬', '안동 하회마을',\n","        '수원화성', '부산 감천문화마을', '독도', '창녕 우포늪', '합천 해인사', '서울 5대궁궐',\n","        '남산타워', '경주 황리단길', '신사동 가로수길', '이태원 경리단길']\n"," \n","extreme= ['통영 어드벤처 타워', '제주도  스쿠버다이빙', '단양 패러글라이딩', \n","          '강원 내린천 래프팅', '충주 스카이다이빙', '하남 스포츠몬스터', '서울 한강 워터 제트팩', \n","          '일산 인공 서핑', '영월 동강래프팅', '여수 스카이플라이', '문경 패러글라이딩', \n","          '경남 하동 하동알프스레포츠', '인천 스카이 짚라인', '강화 루지', '통영 루지', '해운대 스카이캡슐',\n","          '광안리 요트투어', '광안리 해양레포츠', '송도 케이블카', '여수 케이블카']\n"," \n","movie=['크루엘라', '매드맥스', '탑건', '하울의 움직이는 성', '센과 치히로의 행방불명', '토이스토리', '이웃집토토로', \n","       '업', '모아나', '겨울왕국', '코코', '인사이드 아웃', '너의 이름은', '범죄도시', '극한직업', '신과함께', '어벤져스',\n","       '미션임파서블', '스파이더맨', '베놈', '알라딘', '주토피아', '데드풀', '마루 밑 아리에티', '몬스터주식회사', '곰돌이 푸',\n","       '니모를 찾아서', '7번방의 선물', '늑대소년', '기생충', '미나리', '괴물', '해운대', '왕의남자', '변호인', '형', '엑시트',\n","       '명량', '한산', '건축학개론', '도둑들', '베테랑', '암살', '부산행', '관상', '택시운전사', '태극기 휘날리며', '청년경찰',\n","       '스물', '더 테러 라이브', '검은사제들', '검사외전', '전우치', '추격자']\n"," \n","\n","k_balad=['Timeless - SG워너비',\n","'밤하늘의 별을 (2020) - 경서',\n","'어떻게 이별까지 사랑하겠어, 널 사랑하는 거지 - AKMU (악동뮤지션)',\n","'서울의 잠 못 이루는 밤 (Feat. 이수현) - 10CM',\n","'잠이 오질 않네요 - 장범준',\n","'I Love U-성시경',\n","'내사람 (Partner For Life) - SG워너비',\n","'취기를 빌려 - 산들',\n","'안녕 (Hello) - 조이',\n","'밤편지 - 아이유(IU)',\n","'너의 모든 순간 - 성시경',\n","'좋을텐데 (If Only) (Feat. 폴킴) - 조이',\n","'봄 안녕 봄 - 아이유(IU)',\n","'Love poem - 아이유(IU)',\n","'아이와 나의 바다 - 아이유(IU)',\n","'벌써 일년 - 반하나& MJ(써니사이드)',\n","'이렇게 좋아해 본 적이 없어요 - CHEEZE (치즈)',\n","'헤픈우연 - 헤이즈',\n","'어린왕자 - 려욱',\n","'광화문에서 - 규현',\n","'나비무덤 - Take',\n","'청소 - The Ray',\n","'나를 잊지 말아요 - 허각',\n","'사월의 눈 - 허각',\n","'보고싶은날엔 - 박지헌',\n","'그녀를 사랑해줘요 - 하동균',\n","'저녁하늘 - 에일리',\n","'가을안부 - 먼데이키즈',\n","'시간과 낙엽 - 악동뮤지션',\n","'새벽가로수길(feat.송유빈) - 백지영',\n","'너였다면 - 정승환',\n","'선물 - 멜로망스',\n","'이럴거면 그러지말지 - 백아연',\n","'안아줘 - 정준일',\n","'거북이 - 다비치',\n","'모든날 모든순간 - 폴킴',\n","'취중고백 - 멜로망스',\n","'오래된 노래 - 스텐딩에그',\n","'Little star - 스텐딩에그',\n","'All of my life - 박원',\n","'두사랑 - 다비치',\n","'아로하 - 조정석',\n","'미워도 사랑하니까 - 다비치',\n","'기대 - 나윤권',\n","'그라데이션 - 10cm',\n","'그리워하다 - 비투비',\n","'봄날의 기억 - 비투비',\n","'널 사랑하지않아 - 어반자카파'\n","'눈의 꽃 - 박효신',\n","'기억을 걷는 시간 - 넬'\n","]\n"," \n","k_dance=[\n","'Butter - 방탄소년단',\n","'Next Level - aespa',\n","'Dun Dun Dance - 오마이걸(OH MY GIRL)',\n","'치맛바람 (Chi Mat Ba Ram) - 브레이브걸스(Brave Girls)',\n","'Alcohol-Free - TWICE(트와이스)',\n","\"롤린 (Rollin') - 브레이브걸스(Brave Girls)\",\n","'라일락 - 아이유(IU)',\n","'ASAP - STAYC(스테이씨)',\n","'Dynamite - 방탄소년단',\n","'상상더하기 - MSG워너비',\n","'Celebrity - 아이유(IU)',\n","'상상더하기 - 라붐(LABOUM)',\n","'Ready to love - 세븐틴',\n","'Dolphin - 오마이걸(OH MY GIRL)',\n","'Lovesick Girls - BLACKPINK',\n","'어푸(Ah puh) - 아이유(IU)',\n","'Loving U - 씨스타',\n","'Hot issue - 포미닛',\n","'왜(Keep your head down) - 동방신기',\n","'Catch Me - 동방신기',\n","'Shock - 비스트',\n","'남자가 사랑할 때 - 인피니트',\n","'추격자 - 인피니트',\n","'내꺼하자 - 인피니트',\n","'fiction - 비스트',\n","'파라다이스 - 인피니트',\n","'Bad - 인피니트',\n","'으르렁 - 엑소',\n","'MAMA - 엑소',\n","'중독 - 엑소',\n","'다칠 준비가 돼있어 - 빅스',\n","'기적 - 빅스',\n","'도원경 - 빅스',\n","'Hide - 빅스',\n","'movie - 비투비',\n","'After Like - 아이브',\n","'Eleven - 아이브',\n","'Love Dive - 아이브',\n","'Attention - 뉴진스',\n","'카니발 - 가인',\n","'피어나 - 가인',\n","'식스센스 - 브라운아이드걸스',\n","'종소리 - 러블리즈',\n","'다시만난세계 - 소녀시대',\n","'도깨비불 - aespa',\n","'Hype boy - 뉴진스',\n","'Goodbye Summer - 에프엑스',\n","'첫사랑니 - 에프엑스',\n","'4walls - 에프엑스',\n","'Hello future - 엔시티드림',\n","'Happiness - 레드벨벳',\n","'러시안룰렛 - 레드벨벳',\n","'View - 샤이니',\n","'Sherlock - 샤이니',\n","'Heartbeat - 2PM',\n","'우리집 - 2PM',\n","'Tell me - 원더걸스',\n","\n","\n","\n","]\n"," \n","k_hip=[\n","'마.피.아. In the morning-ITZY(있지)',\n","'맛 (Hot Sauce)-NCT DREAM',\n","'밸런스 게임-투모로우바이투게더',\n","'GAM3 BO1-세븐틴',\n","'비도 오고 그래서 (Feat. 신용재)-헤이즈 (Heize)',\n","'METEOR-창모(CHANGMO)',\n","'DNA-방탄소년단',\n","'IDOL-방탄소년단',\n","'FAKE LOVE-방탄소년단',\n","'피 땀 눈물-방탄소년단',\n","'사이렌-호미들',\n","'멜로디-ASH ISLAND',\n","'I NEED U-방탄소년단',\n","'아무노래-지코 (ZICO)',\n","'어떻게 지내 (Prod. By VAN.C)-오반(OVAN)',\n","'Rainy day (Feat. ASH ISLAND, Skinny Brown)-PATEKO(파테코)',\n","'뚜두뚜두 (DDU-DU DDU-DU)-BLACKPINK',\n","'죽일놈 - 다이나믹듀오',\n","'불꽃놀이 - 다이나믹듀오',\n","'TV를 껐네(feat. Tasha, Kwon Jungyeol OF 10CM) - 리쌍',\n","'Forever - 비아이',\n","'아무노래 - 지코',\n","'너는 나 나는 너 - 지코',\n","'거북선(feat.팔로알토) - Ja Mezz, Andup (앤덥), MINO (송민호)',\n","'Born Hater - 에픽하이',\n","'Fly - 에픽하이',\n","'Love Love Love - 에픽하이',\n","'그땐 그땐 그땐 - 슈프림팀',\n","'왜 - 슈프림팀',\n","'노땡큐 (Feat. MINO, 사이먼 도미닉, 더콰이엇) - 에픽하이',\n","'party(SHUT DOWN)(feat. 크러쉬(Crush)) - 식케이',\n","'flex - 기리보이',\n","'시차 - 우원재',\n","'바코드 - 김하온&이병재',\n","'리무진 (Feat. MINO) - 비오',\n","'아쿠아맨 - 빈지노',\n","'회전목마 (Feat. Zion.T, 원슈타인) - 소코도모 ',\n","'보트 (Boat) - 죠지',\n","'외톨이 - 아웃사이더',\n","'몽환의숲(feat.이루마) - 키네틱플로우',\n","'인스타그램 - 딘',\n","'D(half moon) - 딘',\n","'Red sun - 행주',\n","'Jackpot - 블락비'\n","]\n","\n","\n","food = [\"삼계탕\", \"삼겹살\", \"곱창\", \"찜닭\", \"오리고기\", \"소고기\", \n","          \"국밥\", \"닭도리탕\", \"낙곱새\", \"라면\", \"비빔밥\", \"칼국수\", \n","          \"수제비\", \"갈비\", \"제육볶음\", \"스테이크\", \"파스타\", \"필라프\", \"감바스\", \"리조또\", \"샐러드\", \n","           \"피자\", \"빠에야\", \"플래터\", \"스튜\", \"짜장면\", \"뿌팟퐁커리\", \"팟타이\", \"나시고랭\", \"쌀국수\", \"미고랭\",\n","         \"카레\", \"마라탕\", \"마라샹궈\", \"훠궈\", \"돈까스\", \"월남쌈\", \"라멘\", \n","         \"탄탄멘\", \"규동\", \"꿔바로우\", \"똠양꿍\", \"물냉면\"]\n","\n","spicy = [\"엽떡 3단계\", \"불닭볶음면\", \"송주불냉면\", \"실비김치\", \"불닭발\", \n","         \"김치찜\", \"김치찌개\", \"감자탕\", \"짬뽕\", \"닭발\", \"부대찌개\",\n","         \"순두부찌개\", \"아구찜\", \"해물찜\", \"육개장\", \"낙지볶음\", \"쭈꾸미\", \n","         \"돼지갈비찜\", \"소꼬리찜\", \"비빔냉면\", \"짚신매운갈비찜\"]\n","\n","dessert = [\"와플\", \"마카롱\", \"빙수\", \"크로크모슈\", \"케이크\", \"허니바게트볼\",\n","           \"치즈케이크\", \"레몬파운드케이크\", \"쿠키\", \"허니브레드\", \"오믈렛\", \"베이글\",\n","           \"휘낭시에\", \"초코케이크\", \"말차스콘\", \"마들렌\", \"츄러스\", \"다쿠아즈\", \"초코브라우니\",\n","           \"도넛\", \"꽈배기\", \"카스테라\", \"소금빵\", \"크로플\", \"크로넛\", \"에그타르트\", \"크로넛\", \"크로와상\"]\n","\n","snack = [\"닭강정\", \"양꼬치\", \"핫윙\", \"소떡소떡\", \"가라아게\", \"콘치즈\", \"감자튀김\", \n","         \"치킨너겟\", \"치킨\", \"나쵸\", \"소시지\", \"버터오징어구이\", \"핫도그\", \n","         \"해쉬브라운\", \"맥모닝\", \"맥치킨\", \"맥윙\", \"스낵랩\", \"치즈스틱\", \"꼬깔콘\", '프링글스',\n","         \"포카칩\", '빼빼로', '타코야끼', '오코노미야끼', '김치전', '감자전', '부추전', '뻥튀기',\n","         '약과', '군밤', '붕어빵', '씨앗호떡', '호두과자', '계란빵', '핫바', '젤리', '아이셔',\n","         '새콤달콤', '치즈볼', '쥐포', '콜팝', '빈대떡', '순대']\n","\n","coffee = [\"아메리카노\", \"콜드브루\", \"바닐라라떼\", \"카페라떼\", \"카라멜마키아또\",\n","          \"카페모카\", \"카페모카프라페\", \"연유라떼\", \"화이트 모카\",\n","          \"민트모카\", \"헤이즐넛라떼\", \"에스프레소\", '아인슈패너', '플랫화이트', '맥심아이스커피',\n","          '달고나라떼', '아샷추', '레쓰비']\n","\n","beverage = [\"초코 라떼\", \"민트초코 라떼\", \"밀크티\", \"흑당 버블티\", \"레몬차\", \"자몽차\", '허니자몽블랙티',\n","            \"유자차\", \"모히토\", \"요거트 스무디\", \"블루베리 스무디\", \"딸기 스무디\", \"애플망고 스무디\",\n","            \"레몬 에이드\", \"자몽 에이드\", \"딸기 생과일 주스\", \"오곡 프라페\", \"쿠앤크 프라페\",\n","            '유자애플티', '타로버블티', '오레오쿠키스무디', '밀크쉐이크', '생초콜릿라떼', '딸기쉐이크',\n","            '청포도에이드', '딸기바나나주스', \"키위 생과일 주스\", '사과케일주스', '비타500', '알로에주스',\n","            '식혜', '컨피던스', '소주', '맥주', '칵테일', '와인', '막걸리', '샴페인']\n","\n","\n","\n","f0 = [heal,extreme, movie,k_dance,k_hip,spicy,dessert,snack,coffee,beverage, food]\n","f1 = [extreme,movie,k_dance,k_hip,spicy,dessert,snack,coffee,beverage]\n","f2 = [heal,movie,k_dance,k_balad,dessert,food,beverage]"],"metadata":{"id":"xzp_KRtCkdXj","executionInfo":{"status":"ok","timestamp":1665810832525,"user_tz":-540,"elapsed":17,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# import sys\n"," \n","# def printsave(text):\n","#     file = open('/content/drive/MyDrive/result/result.txt','w')\n","#     print(text)\n","#     print(text,file=file)\n","#     file.close()"],"metadata":{"id":"5XZMgtSM8nde","executionInfo":{"status":"ok","timestamp":1665810832526,"user_tz":-540,"elapsed":17,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# import random\n","\n","# if (a == '편안함') | (a == '기쁨') | (a == '행복') | (a == '감사') | (a == '만족') | (a == '흥미로움') | (a == '보통'):\n","#   pick = random.choice(f0)\n","#   print('제가 생각하기에는 오늘의 감정은 '+ a + '인 것 같아요!\\n오늘 {0}을(를) 추천드려요!'.format(random.choice(pick)))\n","\n","# elif (a == '분노') | (a == '불만') | (a == '짜증') | (a == '답답')| (a == '조롱'):\n","#   pick = random.choice(f1)\n","#   print('제가 생각하기에는 오늘의 감정은 '+ a + '인 것 같아요.\\n 오늘 {0} 어때요?'.format(random.choice(pick)))\n","\n","# else:\n","#   pick = random.choice(f2)\n","#   printsave('제가 생각하기에 오늘의 감정은 '+ a + '인 것 같아요.\\n오늘의 그대를 위해 {0} 어때요?\\n오늘도 수고했어요 언제나 그대를 응원합니다.'.format(random.choice(pick)))"],"metadata":{"id":"vra2sot3cd8Z","executionInfo":{"status":"ok","timestamp":1665810832526,"user_tz":-540,"elapsed":17,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# 최종코드 \n","import threading\n","import os\n","import sys\n","def printsave(text):\n","    file = open('/content/drive/MyDrive/result/result.txt','w')\n","    print(text)\n","    print(text,file=file)\n","    file.close()\n","\n","def emotion():\n","  # timer = threading.Timer(5, emotion)\n","  # timer.start()\n","  while True:\n","    if os.path.isfile(\"/content/drive/MyDrive/text_file/test.txt\"):\n","      text = open('/content/drive/MyDrive/text_file/test.txt', 'r')\n","      text = text.read().splitlines()\n","      # print(text)\n","\n","      str = ''.join(text)\n","      a = predict(str, model)\n","\n","      import random\n","\n","      if (a == '편안함') |  (a == '감사') | (a == '만족') | (a == '흥미로움') | (a == '보통'):\n","        pick = random.choice(f0)\n","        printsave('제가 생각하기에 오늘의 감정은 '+ a + '인 것 같아요!\\n오늘 {0}을(를) 추천드려요!\\n그대의 내일은 더욱더 빛나길 기도할게요.❤'.format(random.choice(pick)))\n","\n","\n","      elif (a == '기쁨') | (a == '행복') :\n","        pick = random.choice(f0)\n","        printsave('제가 생각하기에 오늘의 감정은 '+ a + '인 것 같아요!\\n너무 부럽네요!\\n오늘 {0} 고?😎 '.format(random.choice(pick)))\n","\n","      elif (a == '분노') | (a == '불만') | (a == '짜증') | (a == '답답'):\n","        pick = random.choice(f1)\n","        printsave('제가 생각하기에 오늘의 감정은 '+ a + '인 것 같아요.\\n오늘 {0} 어때요?\\n기분이 한결 나아질 거에요😀!'.format(random.choice(pick)))\n","\n","      elif  (a=='불안'):\n","          printsave('생각이 많을땐 레몬사탕이지!\\n레몬사탕 먹고 털어버려요!🍋')\n","\n","      elif (a == '조롱'):\n","          pick = random.choice(f1)\n","          printsave('누군가를' +a+ '하는 당신, 당신이 있어 오늘 하루도 따뜻합니다.😁 \\n 그런 의미에서 오늘 {0} 로 땡길까요?')\n","\n","      else:\n","        pick = random.choice(f2)\n","        printsave('제가 생각하기에 오늘의 감정은 '+ a + '인 것 같아요.\\n오늘의 그대를 위해 {0} 어때요?\\n오늘도 수고했어요 언제나 그대를 응원할게요.🎈'.format(random.choice(pick)))\n","\n","      break\n","    else : \n","      continue"],"metadata":{"id":"2Wh8QciF4Zog","executionInfo":{"status":"ok","timestamp":1665810832526,"user_tz":-540,"elapsed":16,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["emotion()\n","os.remove('/content/drive/MyDrive/text_file/test.txt')"],"metadata":{"id":"mFidrz5V58uV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665821185132,"user_tz":-540,"elapsed":711,"user":{"displayName":"Hyeri Cho","userId":"04168557094514846908"}},"outputId":"5031d046-b730-493d-ba74-70ce87b1d72a"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["제가 생각하기에 오늘의 감정은 행복인 것 같아요!\n","너무 부럽네요!\n","오늘 시차 - 우원재 고?😎 \n"]}]}]}